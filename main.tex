%Document Props
%FONT SIZE
%DOC CLASS
\documentclass[12pt, a4paper]{report}

%Packages
\usepackage{fullpage} %1-inch margins
\usepackage{setspace} %double space
\usepackage[backend=bibtex8]{biblatex}
\addbibresource{ref.bib}
%Change Chapter format in report class
\usepackage{titlesec} 
\titleformat{\chapter}[block]
  {\normalfont\huge\bfseries}{\thechapter.}{1em}{\Huge}
\titlespacing*{\chapter}{0pt}{-19pt}{0pt}

%Graphics package and relative path
\usepackage{graphicx}
\graphicspath{{images/}}

% For other font sizes
% !incompatible with fullpage
%\usepackage{extsizes}

\onehalfspacing
% ----------------------------------------------------------------------------------------------
\begin{document}

% Outer Cover Page
\pagestyle{empty}
\begin{titlepage}
\vspace*{0.2cm}
\begin{center} \textbf{A REPORT\\ON} \end{center}
\begin{center} \textbf{{\Large AUTOMATIC LAND COVER CLASSIFICATION OF MULTI-TEMPORAL SATELLITE IMAGES}} \end{center}
\begin{center} \textbf{BY} \end{center}
\begin{center} 
{\Large 
	\begin{tabular}{c c}
	Guntaas Singh & 2018A7PS0269P\\
	Nisarg Vora & 2018A7PS0254P
	\end{tabular}
}
\end{center}
\begin{center} \textbf{AT} \end{center}
\begin{center} \includegraphics{iirs.png} \end{center}
\begin{center} {\Large Indian Institute of Remote Sensing, Dehradun} \end{center}
\begin{center} A Practice School - I station of \end{center}
\begin{center} {\includegraphics{bits.png}} \end{center}
\begin{center} {\Large Birla Institute of Technology and Science, Pilani} \end{center}
\begin{center} June, 2020 \end{center}
\end{titlepage}
\pagebreak

% Inner Cover Page
\begin{titlepage}
\vspace*{0.3cm}
\begin{center} \textbf{A REPORT\\ON} \end{center}
\begin{center} \textbf{{\Large AUTOMATIC LAND COVER CLASSIFICATION OF MULTI-TEMPORAL SATELLITE IMAGES}} \end{center}
\begin{center} \textbf{BY} \end{center}
\begin{center}
	\begin{tabular}{c c c}
		\textbf{ID Number} & \textbf{Name} & \textbf{Branch} \\
		2018A7PS0269P & Guntaas Singh & B.E. (Hons.) Computer Science \\
		2018A7PS0254P & Nisarg Vora  & B.E. (Hons.) Computer Science \\
	\end{tabular} 
\end{center}
\begin{onehalfspace}
\begin{center} \textbf{Prepared in the partial fulfillment of the} \end{center}
\begin{center} Practice School - I course \end{center}
\begin{center} \textbf{AT} \end{center}
\begin{center} \includegraphics{iirs.png} \end{center}
\begin{center} {\Large Indian Institute of Remote Sensing, Dehradun} \end{center}
\begin{center} A Practice School - I station of \end{center}
\begin{center} {\includegraphics{bits.png}} \end{center}
\begin{center} {\Large Birla Institute of Technology and Science, Pilani} \end{center}
\begin{center} June, 2020 \end{center}
\end{onehalfspace}
\end{titlepage}
\pagebreak

% Acknowledgements
\setcounter{secnumdepth}{0}
\section{Acknowledgements}
\pagestyle{plain}
\pagenumbering{roman}
\setcounter{page}{3}
\paragraph{}
We would sincerely like to thank the Director of Indian Institute of Remote Sensing, Dr. Prakash Chauhan, for giving us an opportunity to work in this organization and gain a significant amount of exposure to corporate work culture, ethics, and etiquettes to be followed while working in a professional environment.
\paragraph{}
We would like to extend our most sincere gratitude to our project in-charge, Dr. Hari Shanker Srivastava, Head of the Programme Planning and Evaluation Group (PPEG) at IIRS, for providing us with the opportunity to work with him on this project, and his guidance and mentorship during the same.
\paragraph{}
We wish to extend our gratitude to the faculty in charge of the PS-I program at IIRS, Dr. Rekha A., Assistant Professor at BITS Pilani - Bangalore Center, for her guidance and advice during the PS-I program, and her helpfulness and responsiveness while addressing all the concerns we raised during the same.
\paragraph{}
In addition, we would also like to thank the members of the Practice School Division, who have worked very hard for operating the PS-I programme remotely to ensure that we have a seamless learning experience.
\pagebreak

% Details and abstract
\begin{center}  
\textbf {BIRLA INSTITUTE OF SCIENCE AND TECHNOLOGY\\
PILANI (RAJASTHAN)\\
Practice School Division}
\end{center}
\begin{onehalfspace}
\textbf{Station:} Indian Institute of Remote Sensing \\
\textbf{Centre:} Dehradun\\
\textbf{Duration:} From 18th May, 2020 to 27th June, 2020 \\
\textbf{Date of start:} 18th May, 2020 \\
\textbf{Date of submission:} 4th June, 2020 \\
\textbf{Title of project:} Automatic Land Cover Classification of Multi-temporal Satellite Images
\begin{center}
\begin{tabular}{c c c}
\textbf{ID Number} & \textbf{Name} & \textbf{Branch} \\
2018A7PS0269P & Guntaas Singh & B.E. (Hons.) Computer Science \\
2018A7PS0254P & Nisarg Vora  & B.E. (Hons.) Computer Science \\
\end{tabular} 
\end{center}
\textbf{Name of guide:} Dr. Hari Shanker Srivastava \\
\textbf{Designation:} Scientist/Engineer - SG. Group Head, Programme Planning and Evaluation Group (PPEG). \\
\textbf{Name of PS faculty:} Dr. Rekha A. 

	\section{Abstract}
	\paragraph{}
	Blah
\end{onehalfspace}
\newpage

%Response sheet
\begin{center}  
\textbf {BIRLA INSTITUTE OF SCIENCE AND TECHNOLOGY\\
PILANI (RAJASTHAN)\\
Practice School Division\\
Response Option Sheet}
\end{center}
\begin{onehalfspace}
\textbf{Station:} Indian Institute of Remote Sensing \\
\textbf{Centre:} Dehradun
\begin{center}
\begin{tabular}{c c c}
\textbf{ID Number} & \textbf{Name} & \textbf{Branch} \\
2018A7PS0269P & Guntaas Singh & B.E. (Hons.) Computer Science \\
2018A7PS0254P & Nisarg Vora  & B.E. (Hons.) Computer Science \\
\end{tabular} 
\end{center}
\textbf{Title of project:} Automatic Land Cover Classification of Multi-temporal Satellite Images\\
\begin{center}
\begin{tabular}{|p{1cm}|p{10cm}|p{3cm}|}
\hline
\textbf{Code No.} & \textbf{Response Option} & \textbf{Course No.(s) and Name} \\
\hline
1 & A new course can be designed out of this project. & ~\\
\hline
2 & The project can help modification of the course content of some of the existing Courses & ~\\
\hline
3 & The project can be used directly in some of the existing Compulsory Discipline Courses (CDC)/ Discipline Courses Other than Compulsory (DCOC)/ Emerging Area (EA), etc. Courses & ~\\
\hline
4 & The project can be used in preparatory courses like Analysis and Application Oriented Courses (AAOC)/ Engineering Science (ES)/ Technical Art (TA) and Core Courses. & ~\\
\hline
5 & This project cannot come under any of the above mentioned options as it relates to the professional work of the host organization. &~ \\
\hline
\end{tabular} 
\end{center}
\end{onehalfspace}
\vspace*{0.5cm}
\textbf{Signature}\\
\textbf{Date: }
\newpage

% Table of Contents
\tableofcontents
\newpage

% INTRODUCTION
\setcounter{page}{1}
\setcounter{secnumdepth}{1}
\chapter{Introduction}
\pagenumbering{arabic}
\section{About IIRS}
Blah
\subsection{WHAT}
It is a long established fact that a reader will be distracted by the readable content of a page when looking at its layout. The point of using Lorem Ipsum is that it has a more-or-less normal distribution of letters, as opposed to using 'Content here, content here', making it look like readable English. Many desktop publishing packages and web page editors now use Lorem Ipsum as their default model text, and a search for 'lorem ipsum' will uncover many web sites still in their infancy. Various versions have evolved over the years, sometimes by accident, sometimes on purpose (injected humour and the like).\\

\newpage

% ____________________________

% METHODOLOGY
\chapter{Methodology}
\section{Image Classification}

Image classification is a standard task in computer vision. In general, the image classification problem involves assigning one  label out of a given fixed set of discrete labels to the input image on the basis of its visual content. While this is a trivial task for humans, robust image classification is a big challenge for a machine. To the computer, the image is just a grid of numbers which entirely change in unreliable ways with variations in viewpoint, illumination, occlusion, etc. As a result, there is no obvious algorithm which solves this problem. However, a data driven approach of providing the machine with many examples of each class and use of machine learning techniques has shown to be useful.\cite{cs231n}
\paragraph{}
There are different ways in which these techniques can be applied for classification of satellite imagery.
\subsection{Pixel Based Approach}
In typical satellite images, pixel sizes are generally similar in size to the objects of interest. Most of the methods for image analysis using remote sensing data work on a per-pixel basis. However, with advances in remote sensing technology, the spatial resolution has become finer than the typical objects of interest, leading to an increase in within-class variablilty.\cite{eyesky}
\subsection{Object Based Approach}
The term "objects" represents meaningful semantic entities or scene components that are distinguishable in an image.\cite{eyesky} This approach involves the partition of the image into meaningful geographical objects that share relatively homogeneous spectral, color, etc.
\subsection{Semantic Approach}
This aims to label each scene image with a specific semantic class. Here, a scene image usually refers to a local image patch manually extracted from large scale remote sensing images that contain explicit semantic classes.\cite{eyesky}

\section{Deep Learning and Neural Networks}
Application of traditional machine learning techniques requires handcrafted features, developing which demands a considerable amount of engineering skill and domain expertise. This, however, is not true for neural networks, which automatically learn these features from data using a general-purpose learning procedure.\cite{eyesky, cs231n} Despite having been around for decades, neural networks have garnered much attention only in the last few years on account of the availability of increased computaional power and large amounts of data.
\paragraph{}
A standard neural network consists of many simple, connected processors called neurons, each producing a sequence of real-valued activations. Input neurons get activated through sensors perceiving the environment, other neurons get activated through weighted connections from previously active neurons. \cite{schmidhuber2015deep} Each neuron can be seen as a single unit applying a non-linear activation function (such as sigmoid, tanh, ReLU) to a linear combination of the input activations to the neuron.\cite{cs229}
\begin{figure}[h]
\centering
\includegraphics[width=0.5\textwidth]{nn1.png}
\caption{A single neuron.}\cite{cs229}
\end{figure}
\paragraph{}
These single neurons can be stacked so that one neuron passes its output as input into the next neuron. The resulting network of neurons can, hence, consist of several layers of neurons, each with their own learnable weights and biases. Used in conjunction with an appropriate loss function and optimization algorithm, such a network can be used to learn any complex function, if sufficient data is available for training. Forward propagation through the network yields its prediction for a given input. This prediction is compared with the actual class label, and the loss is computed. Backward Propagation is used to compute the gradients of the loss function with respect to the parameters, which are then used by the optimization algorithm to adjust the parameters and minimize the loss over a number of iterations.
\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{nn2.png}
\caption{A two layer neural network with fully connected layers.}\cite{cs231n}
\end{figure}
\newpage

\section{Convolutional Neural Networks}
\paragraph{}
Regular neural networks do not scale well to full images. If the input to the neural network is a 200x200 RGB image, the number of weights for each neuron will be 200*200*3 = 120,000 weights. For large networks, the total number of learnable parameters become very large and lead the model to potentially overfit the training data, unless the training set is adequately large.
\paragraph{}
A convolutional neural network (CNN) is a sequence of layers. Each layers transforms an input volume (images are represented as a three dimensional matrix) of activations to another with some differentiable function which may or may not have parameters.\cite{cs231n, dlai4} These layers are of three main types:
\subsection{Convolutional Layer}
This is the core building block for convolutional networks. It is based on the convolution operation on images.
\paragraph{}
Each convolutional layer of a CNN consists of $N$ kernels or filters of a certain volume of neurons sized $f \times f \times d$, with $f$ being the spatial dimension and $d$ being the number of feature channels of the kernel, which is same as the number of channels in the image at its input ($D_{i}$). Every one of these filters is convolved with a corresponding volume of the input image, and is slid through the entire image of size $H_{i} \times W_{i} \times D_{i}$. Convolution refers to the summation of the element-wise dot product of the neurons in each filter with the corresponding values in the input, for each position in which the filter is aligned with the image. Based on this notion, a convolution with a single filter at each layer results in a two dimensional output of a certain size. \cite{cs231n, muruganandham2016semantic, dlai4}
\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{cnn1.jpg}
\caption{The convolution operation performed using a 3x3 filter on a 5x5x1 image.}\cite{fathi2018deep}
\end{figure}
\paragraph{}
The intervals with which the filter moves in each spatial dimension is decided by the \textbf{stride} $s$. In order to prevent undue shrinkage of the volume along the spatial dimension, the image can be padded with pixels along the outer edges. The width of this \textbf{padding}, in pixels, is given by another hyperparameter, $p$.\cite{dlai4, muruganandham2016semantic} The convolution operation is repeated for each of the $N$ filters, and the resulting $N$ activation maps are stacked together across the third dimension giving an output volume of dimensions:\\
\begin{displaymath}
H_{o}=\frac{H_{i}-f+2p}{s+1}
\end{displaymath}
\begin{displaymath}
W_{o}=\frac{W_{i}-f+2p}{s+1}
\end{displaymath}
\begin{displaymath}
D_{o}=N
\end{displaymath}
\printbibliography[title={References}]
\end{document}
